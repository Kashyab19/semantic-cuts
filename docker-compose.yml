version: "3.8"

services:
  inference:
    build: .
    container_name: inference_engine
    command: python3 app/server.py
    ports:
      - "8001:8001"
    volumes:
      - .:/app
    environment:
      - CUDA_VISIBLE_DEVICES=0 # Optional: Only if you have NVIDIA GPU setup
    restart: always

  # --- INFRASTRUCTURE ---
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
    volumes:
      - ./qdrant_data:/qdrant/storage
    restart: always

  redpanda:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    container_name: redpanda
    command:
      - redpanda start
      - --smp 1
      - --memory 1G
      - --reserve-memory 0M
      - --overprovisioned
      - --node-id 0
      - --check=false
      - --kafka-addr PLAINTEXT://0.0.0.0:9092,OUTSIDE://0.0.0.0:9094
      - --advertise-kafka-addr PLAINTEXT://redpanda:9092,OUTSIDE://localhost:9094
    ports:
      - "9094:9094"
      - "8081:8081"
    volumes:
      - ./redpanda_data:/var/lib/redpanda/data
    restart: always

  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"

volumes:
  shared_video_storage:
